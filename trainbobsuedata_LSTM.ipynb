{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Andrew LSTM.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "K7SFsCTPePPq"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import matplotlib.pyplot as pp\n",
        "import numpy as np\n",
        "\n",
        "import random\n",
        "import time\n",
        "import math\n",
        "\n",
        "import pickle\n",
        "\n",
        "DEVICE = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "blbJvMMMAqhH"
      },
      "source": [
        "## Classes"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ai5b1iLi9hyH"
      },
      "source": [
        "class LSTMCell(nn.Module):\n",
        "  def __init__(self, n_in, n_hid):\n",
        "    super(LSTMCell, self).__init__()\n",
        "    self.forget = nn.Linear(n_in+n_hid, n_hid)\n",
        "    self.input = nn.Linear(n_in+n_hid, n_hid)\n",
        "    self.gate = nn.Linear(n_in+n_hid, n_hid)\n",
        "    self.output = nn.Linear(n_in+n_hid, n_hid)\n",
        "\n",
        "    \n",
        "  def forward(self, x, tupHC):\n",
        "    h, c = tupHC\n",
        "    xs = x.unsqueeze(0)\n",
        "    new_x = torch.cat((h, xs), dim=1) #customize per data\n",
        "    f_gate = torch.sigmoid(self.forget(new_x))\n",
        "    i_gate = torch.sigmoid(self.input(new_x))\n",
        "    g_gate = torch.tanh(self.gate(new_x))\n",
        "    o_gate = torch.sigmoid(self.output(new_x))\n",
        "    new_c = f_gate * c + (i_gate*g_gate) # all elementwise\n",
        "    new_h = o_gate * torch.tanh(new_c)\n",
        "    return (new_h, new_c)\n",
        "  \n",
        "class LSTMNet(nn.Module):\n",
        "    def __init__(self, n_in, n_hid, n_out):\n",
        "      # use LSTM to map sequence of characters to some latent feature representation -> use this latent feature representation to do classification on origin\n",
        "      super(LSTMNet, self).__init__()\n",
        "      self.n_hid = n_hid\n",
        "      self.encode = LSTMCell(n_in, n_hid)\n",
        "      self.decode = LSTMCell(n_in, n_hid)\n",
        "      self.fc = nn.Linear(n_hid, n_out)\n",
        "\n",
        "    def forward(self, xs, hidden=None, ctx=None):\n",
        "      # xs is tuple of primer and ground, tensor sentences\n",
        "      primer, ground = xs\n",
        "      if hidden is None:\n",
        "        hidden = self.init_hidden()\n",
        "        ctx = self.init_hidden()\n",
        "        \n",
        "      output = torch.Tensor().cuda()\n",
        "      for i in range(primer.size(0)):\n",
        "        hidden, ctx = self.encode.forward(primer[i], (hidden, ctx))\n",
        "      if(ground is None):\n",
        "        # prediction\n",
        "        last = wordToTen(\"<s>\").cuda()\n",
        "        length = 0\n",
        "        word = \"\"\n",
        "        while(word != \"</s>\" and length < 20):\n",
        "          hidden, ctx = self.decode.forward(last, (hidden, ctx))\n",
        "          output = torch.cat((output, hidden), dim=0)\n",
        "          word = tenToWord(hidden.squeeze(0).cpu())\n",
        "          last = wordToTen(word).cuda()\n",
        "          length += 1\n",
        "      else:\n",
        "        # training\n",
        "        for i in range(ground.size(0)):\n",
        "          hidden, ctx = self.decode.forward(ground[i], (hidden, ctx))\n",
        "          output = torch.cat((output, hidden), dim=0)\n",
        "    #     output = self.log_softmax(self.fc(hidden))\n",
        "  \n",
        "      return output, (hidden, ctx)\n",
        "    \n",
        "    def init_hidden(self):\n",
        "        '''\n",
        "        hidden and cell states init to be zeros of shape hidden dim\n",
        "        '''\n",
        "        return torch.zeros(1, self.n_hid).cuda()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "364EXzY8_fvI"
      },
      "source": [
        "## Load and Parse Data\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vQFIg0OdCTFN"
      },
      "source": [
        "def wordToIdx(wrd):\n",
        "  return wt_map[wrd]\n",
        "\n",
        "def wordToTen(wrd):\n",
        "  return weights_matrix[wordToIdx(wrd)]\n",
        "\n",
        "def lineToTen(line):\n",
        "  ten = torch.zeros((len(line), 200)).cuda()\n",
        "  for i, w in enumerate(line):\n",
        "    ten[i] = wordToTen(w)\n",
        "  return ten #.cuda()\n",
        "\n",
        "def tenToWord(ten):\n",
        "  maximal = [0,-1]\n",
        "  for i, w in enumerate(weights_matrix):\n",
        "    n = (w - ten).norm().item()\n",
        "    if(n < maximal[0] or maximal[1] == -1):\n",
        "      maximal = [n, i]\n",
        "  return list(wt_map.keys())[list(wt_map.values()).index(maximal[1])]\n",
        "\n",
        "def tenToLine(ten):\n",
        "  line = []\n",
        "  cten = ten.cpu()\n",
        "  for t in cten:\n",
        "    line.append(tenToWord(t))\n",
        "  return line"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AVpJY4DCoVaY",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "3de91bec-96fd-4de5-a052-1634b14dd380"
      },
      "source": [
        "# glove = pickle.load(open(\"glove.pkl\", \"rb\"))\n",
        "wt_map = {}\n",
        "\n",
        "target_vocab = []\n",
        "with open(\"bobsue.voc.txt\", \"r\") as r:\n",
        "  for line in r:\n",
        "    target_vocab.append(line.rstrip(\"\\n\"))\n",
        "\n",
        "matrix_len = len(target_vocab)\n",
        "weights_matrix = torch.zeros((matrix_len, 200))\n",
        "words_found = 0\n",
        "\n",
        "for i, word in enumerate(target_vocab):\n",
        "#   try: \n",
        "#     weights_matrix[i] = torch.from_numpy(glove[word])\n",
        "#     words_found += 1\n",
        "#   except KeyError:\n",
        "  weights_matrix[i] = torch.empty(1,200).uniform_(-0.1, 0.1).cuda()\n",
        "  wt_map[word] = i\n",
        "torch.save(weights_matrix, \"weights_rand.pt\")\n",
        "pickle.dump(wt_map, open(\"wt_map.pkl\", \"wb\"))\n",
        "\n",
        "# wt_map = pickle.load(open(\"wt_map.pkl\", \"rb\"))\n",
        "# weights_matrix = torch.load(\"weights_rand.pt\")\n",
        "\n",
        "bobsueTrain = []\n",
        "with open(\"bobsue.seq2seq.train.tsv\", \"r\") as f:\n",
        "  for line in f:\n",
        "    x1, y1 = line.rstrip(\"\\n\").split(\"\\t\")\n",
        "    bobsueTrain.append([lineToTen(x1.split(\" \")), lineToTen(y1.split(\" \"))])\n",
        "    \n",
        "print(tenToLine(bobsueTrain[0][1]))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['<s>', 'She', 'ate', 'quickly', 'and', 'asked', 'to', 'be', 'taken', 'home', '.', '</s>']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "espwUQSK_uVE"
      },
      "source": [
        "## Train Loop"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rmIPn3ticWQO"
      },
      "source": [
        "def train(primer_tensor, ground_tensor, model, optimizer, criterion=F.mse_loss):\n",
        "  optimizer.zero_grad()\n",
        "\n",
        "  hidden, ctx = None, None\n",
        "  output, (hidden, ctx) = model((primer_tensor, ground_tensor), hidden, ctx)\n",
        "\n",
        "  output = output[:-1] # last prediction is meaningless since we fed it </s>\n",
        "  \n",
        "  loss = criterion(output, ground_tensor[1:]) # we're not trying to predict <s>\n",
        "  loss.backward()\n",
        "  optimizer.step()\n",
        "  return output, loss.item()\n",
        "  \n",
        "  \n",
        "def evalCorrect(y_pred, ys):\n",
        "  line = tenToLine(y_pred)\n",
        "  ground = tenToLine(ys)\n",
        "  acc = 0\n",
        "  for q in range(len(y_pred)):\n",
        "    if(line[q] == ground[q+1]):\n",
        "      acc += 1 / len(y_pred)\n",
        "      try:\n",
        "        correct[line[q]] += 1\n",
        "      except:\n",
        "        correct[line[q]] = 1\n",
        "  return acc, line, ground\n",
        "    "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vsvsf95SgemR",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 245
        },
        "outputId": "5a3e38cd-701a-43f4-c92f-fa8376004d61"
      },
      "source": [
        "#def run(): #added\n",
        "#########################\n",
        "#       Training loop   #\n",
        "#########################\n",
        "hparams = {\n",
        "    'learning_rate': 0.1,\n",
        "    'epochs': 30,\n",
        "    'hidden_size': 200,\n",
        "    'logint': 1,\n",
        "    'set_size' : 500 #6036\n",
        "}\n",
        "\n",
        "def randex(all_pairs):\n",
        "#   pair = random.choice(all_pairs)\n",
        "  pair = random.choice(all_pairs[0:hparams['set_size']])\n",
        "#   pair = all_pairs[0]\n",
        "\n",
        "  p = pair[0]\n",
        "  q = pair[1]\n",
        "  return p, q #, lineToTen(p), lineToTen(q)\n",
        "\n",
        "model = LSTMNet(200, hparams['hidden_size'], 200)\n",
        "model.to(DEVICE)\n",
        "opt = torch.optim.Adam(model.parameters(), lr=hparams['learning_rate'])\n",
        "# opt = torch.optim.SGD(model.parameters(), lr=hparams['learning_rate'])\n",
        "# opt = torch.optim.SGD(model.parameters(), lr=hparams['learning_rate'], momentum=0.9, weight_decay=1e-3)\n",
        "\n",
        "\n",
        "epochs = []\n",
        "losses = []\n",
        "all_losses = []\n",
        "some_losses = []\n",
        "accuracy = []\n",
        "corrects = []\n",
        "start = time.time()\n",
        "batch_accs = []\n",
        "correct = {}\n",
        "\n",
        "\n",
        "for e in range(hparams['epochs']):\n",
        "  acc = 0\n",
        "  for i in range(hparams['set_size'] + 1):\n",
        "    pt, gt = randex(bobsueTrain)\n",
        "    y_pred, loss = train(pt, gt, model, opt)\n",
        "    losses.append(loss)\n",
        "    all_losses.append(loss)   \n",
        "    if(i % 100 == 0):\n",
        "      acc, line, ground = evalCorrect(y_pred, gt)\n",
        "      accuracy.append(acc)\n",
        "      some_losses.append(loss)\n",
        "\n",
        "    \n",
        "  if e % hparams['logint'] == 0:\n",
        "    if(e == hparams['epochs'] // 2):\n",
        "      hparams['learning_rate'] = 0.01\n",
        "      for g in opt.param_groups:\n",
        "        g['lr'] = hparams['learning_rate']\n",
        "      print(\"new rate\")\n",
        "    elapsed = (time.time() - start) / 60.\n",
        "    avg_loss = np.mean(losses)\n",
        "#       acc = np.mean(corrects)\n",
        "    acc, line, ground = evalCorrect(y_pred, gt)\n",
        "\n",
        "    print('Epoch {:7} | Loss: {:5.5f} | Acc: {:.3f} | Elapsed: {:.2f}min'.format(e, avg_loss, acc, elapsed))\n",
        "    print(line)\n",
        "    print(ground[1:])\n",
        "    losses = []\n",
        "    batch_accs.append(acc)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch       0 | Loss: 0.00354 | Acc: 0.182 | Elapsed: 0.32min\n",
            "['climbed', 'climbed', 'climbed', 'climbed', 'woman', 'climbed', 'a', 'climbed', '.', '.', '</s>']\n",
            "['Bob', 'eventually', 'found', 'his', 'keys', 'in', 'his', 'coat', 'pocket', '.', '</s>']\n",
            "Epoch       1 | Loss: 0.00286 | Acc: 0.200 | Elapsed: 0.65min\n",
            "['climbed', 'climbed', 'climbed', 'she', 'climbed', 'climbed', '.', 'climbed', '.', '</s>']\n",
            "['At', 'first', ',', 'Bob', 'was', 'winning', 'the', 'game', '.', '</s>']\n",
            "Epoch       2 | Loss: 0.00285 | Acc: 0.182 | Elapsed: 0.99min\n",
            "['climbed', 'onto', 'climbed', 'bit', '.', '.', '.', 'climbed', 'woman', '.', '</s>']\n",
            "['Sue', 'found', 'the', 'perfect', 'blue', 'dress', 'and', 'black', 'shoes', '.', '</s>']\n",
            "Epoch       3 | Loss: 0.00286 | Acc: 0.300 | Elapsed: 1.32min\n",
            "['climbed', 'climbed', 'climbed', 'slow', 'to', 'climbed', '.', 'turned', '.', '</s>']\n",
            "['She', 'was', 'too', 'shy', 'to', 'ask', 'him', 'out', '.', '</s>']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vTEElmYbGiNf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 361
        },
        "outputId": "aa14cab6-6288-43f9-c13c-456e31cfdcef"
      },
      "source": [
        "\n",
        "###\n",
        "\n",
        "# torch.save(weights_matrix, \"weights_rand2.pt\")\n",
        "# print(len(bobsueTrain))\n",
        "# weights_matrix /= 20\n",
        "# print(torch.max(weights_matrix))\n",
        "# model_num += 1\n",
        "# torch.save(model, \"model_{0}.pt\".format(model_num))\n",
        "# order = sorted(correct, key=correct.get, reverse=True)\n",
        "# for i in range(20):\n",
        "#   print(order[i], correct[order[i]])\n",
        "\n",
        "ep = []\n",
        "for i in range(len(accuracy)):\n",
        "  ep.append(i/5)\n",
        "\n",
        "\n",
        "pp.scatter(ep, some_losses)\n",
        "pp.xlabel(\"epochs\")\n",
        "pp.ylabel(\"loss\")\n",
        "pp.show()\n",
        "\n",
        "###"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAgAAAAFYCAYAAAAlTUT9AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 576x396 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-fqj00tvMSPv",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        },
        "outputId": "10d1c587-a347-4a73-d2cb-d32382e9a28a"
      },
      "source": [
        "\n",
        "\n",
        "bobsueTest = []\n",
        "with open(\"bobsue.seq2seq.test.tsv\", \"r\") as f:\n",
        "  for line in f:\n",
        "    x1, y1 = line.rstrip(\"\\n\").split(\"\\t\")\n",
        "    bobsueTest.append([x1.split(\" \"), y1.split(\" \")])\n",
        "    \n",
        "test = random.sample(bobsueTest, 10)\n",
        "for p, g in test:\n",
        "  pred, loss = model((lineToTen(p), None), None, None)\n",
        "  print(tenToLine(pred))\n",
        "\n",
        "    \n",
        "with open(\"bobsue.seq2seq.pred.tsv\", \"w\") as out:\n",
        "  for p, g in bobsueTest:\n",
        "    line = \" \".join(p)\n",
        "    pred, loss = model((lineToTen(p), None), None, None)\n",
        "    line += \"\\t\"\n",
        "    line += \" \".join(tenToLine(pred))\n",
        "    line += \"\\n\"\n",
        "    out.write(line)\n",
        "  "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['spend', 'rock', 'free', '.', '</s>']\n",
            "['spend', 'sauce', 'ever', 'tutor', 'counter', 'to', 'the', 'counter', '.', '</s>']\n",
            "['counter', 'counter', 'counter', 'to', 'the', 'counter', 'counter', 'sauce', 'counter', '.', '</s>']\n",
            "['counter', 'counter', 'counter', 'to', 'the', 'counter', 'counter', 'sauce', 'counter', '.', '</s>']\n",
            "['counter', 'counter', 'counter', 'to', 'the', 'counter', 'counter', 'sauce', 'counter', '.', '</s>']\n",
            "['spend', 'sauce', 'ever', 'tutor', 'counter', 'to', 'the', 'counter', '.', '</s>']\n",
            "['counter', 'counter', 'counter', 'to', 'the', 'counter', 'counter', 'sauce', 'counter', '.', '</s>']\n",
            "['counter', 'counter', 'counter', 'to', 'the', 'counter', 'counter', 'sauce', 'counter', '.', '</s>']\n",
            "['counter', 'counter', 'counter', 'to', 'the', 'counter', 'counter', 'sauce', 'counter', '.', '</s>']\n",
            "['counter', 'counter', 'counter', 'to', 'the', 'counter', 'counter', 'sauce', 'counter', '.', '</s>']\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}